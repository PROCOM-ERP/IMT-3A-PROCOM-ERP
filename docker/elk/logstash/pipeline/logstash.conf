input {
	beats {
		port => 5044
	}

	tcp {
		port => 50000
	}
}

## Add your filters / logstash plugins configuration here
filter {
    if [docker][container][labels][com_docker_compose_project] == "erp" {
        json {
            source => "message"
            target => "spring"
            skip_on_invalid_json => true
        }
            # Check if parsing was successful and if the parsed JSON contains a message field
            if [spring][message] {
                mutate {
                    # Overwrite the original message with the one from parsed JSON
                    update => { "message" => "%{[spring][message]}" }
                    remove_field => ["spring.message"]
                }
                # Merge spring fields into the root event and remove spring container
                ruby {
                    code => '
                        event.get("spring").each do |key, value|
                        next if key == "message" # Skip the message field which is already handled
                        # Handle the @timestamp field specifically if needed
                        if key == "@timestamp" && value.is_a?(String)
                            begin
                                event.set(key, LogStash::Timestamp.coerce(value))
                            rescue => e
                                event.tag("_timestamp_parse_failure")
                            end
                        else
                            event.set(key, value)
                        end
                    end if event.get("spring")
                    event.remove("spring")
                    '
                }
            }
        }

        # Optionally, remove unwanted fields or tags
        mutate {
            remove_tag => ["_grokparsefailure", "_jsonparsefailure", "_rubyexception"]
            # Add or remove fields as necessary
        }
    }
}

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
	}
}
